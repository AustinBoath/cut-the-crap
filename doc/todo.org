
* TODO Filter out background noices that aren't speech
** DONE recognise any speech with an opensource library
   api no allowed (costs money, we're poor)

** DONE audio from video available to libary
   (because wrong format right now, we need RAWW)
   ffmpeg -> audio (mp3) -> RAW 
   
ffmpeg -y -i ./shitty-recording.mkv -map 0:0 -map 0:2 ./shitty-recording.mp3 
ffmpeg -y -i ./shitty-recording.mp3 -f s16le -acodec pcm_s16le -filter:a aresample=resampler=soxr:osr=16000 -ac 1 ./shitty-recording.raw


** TODO Getting timestamps out of RAW and make available
   
*** DONE   Make C function to accept a file, and spit out a list of (TIMERANGE, word) for example: `(8982, 9022) are`


   ... MAGICK FFI happens (Haskell --> C --> Haskell)
     We did tool parts for this.
   Put that result into SRT format (haskell)

20, 30 HELLO
34, 50 WORLD -> WOBLD

** DONE connection between c/haskell (somehow)
   FFI (if we can do it!)

** Worries / woes
   
*** mp3 -> RAW - will time align
Detection may be possible by generating SRT files (and thus subtitles)

It doesn't (lol)

**** DONE Refactor code to be unit testable
     

**** TODO Write test for toDiffTime 
     We should make 1 wordFrame align with the video.
     Then another wordFrame.

     Then do same for another vid.
**** TODO Write some unit test based on observations


**** An idea: we could attempt align silences detected by ffmpeg with those of the speech recognition engine.

*** Does it doe sentences? How will it handle large audio files
I'm affraind this thing can only do small audio files.
